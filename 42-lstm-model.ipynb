{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model without any feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        # Only take the output from the final timestep\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `data` is a DataFrame with your dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('sessions_UK_finalized_len2.csv')\n",
    "\n",
    "\n",
    "# Combine all items into a single list\n",
    "all_items = pd.concat([data['next_item'], data['prev_items'].apply(pd.Series).stack()]).unique()\n",
    "\n",
    "# Create item to index and index to item mappings\n",
    "item_to_index = {item: idx for idx, item in enumerate(all_items)}\n",
    "index_to_item = {idx: item for item, idx in item_to_index.items()}\n",
    "\n",
    "vocab_size = len(item_to_index)  # The total number of unique items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        next_item                prev_items encoded_prev_items\n",
      "0      B0046U4CGS  [B01NCPFGQ3, B01N0U5UDH]             [4024]\n",
      "1      B07QS8M6W4  [B08HLVKVWR, B00I874D4Q]       [1779, 3370]\n",
      "2      B094VMJK1G  [B094VLF9QV, B0B24Z4D3V]             [2374]\n",
      "3      B07YQ1XM6J  [B0177HKHQK, B01HQHGIBY]       [2869, 5891]\n",
      "4      B0B63T3HGD  [B09JXY17B6, B004PYD9QE]             [5401]\n",
      "...           ...                       ...                ...\n",
      "52194  B0BKPXCVHZ  [B08B4T5ZWJ, B08B4T5ZWJ]         [964, 964]\n",
      "52195  B08KS94WMW  [B0BG912PV7, B09Z8C64DT]        [2629, 890]\n",
      "52196  B004AVB4UK  [B0BCLGK9DD, B00VP2SSFG]         [5304, 31]\n",
      "52197  B0BD96VGPW  [B08L6RD61H, B07XTNBQ8G]       [5400, 3734]\n",
      "52198  B07S6C1DZ6  [B07DYBV29C, B07DYBV29C]         [212, 212]\n",
      "\n",
      "[52199 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  \n",
    "\n",
    "# Convert string representation of lists to actual lists\n",
    "data['prev_items'] = data['prev_items'].apply(ast.literal_eval)\n",
    "\n",
    "# Function to encode a single list of item IDs\n",
    "def encode_prev_items(item_list, mapping):\n",
    "    return [mapping[item] for item in item_list if item in mapping]\n",
    "\n",
    "# Apply encoding to each list in 'prev_items'\n",
    "data['encoded_prev_items'] = data['prev_items'].apply(lambda x: encode_prev_items(x, item_to_index))\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(data[['next_item', 'prev_items', 'encoded_prev_items']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52199, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Convert each sequence to a PyTorch tensor\n",
    "sequences = [torch.tensor(seq) for seq in data['encoded_prev_items']]\n",
    "\n",
    "# Pad all sequences to the same length\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "\n",
    "print(padded_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Encode 'next_item'\n",
    "data['encoded_next_item'] = data['next_item'].apply(lambda x: item_to_index[x] if x in item_to_index else None)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now split the data again\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert sequences and targets to PyTorch tensors as before\n",
    "train_sequences = pad_sequence([torch.tensor(seq) for seq in train_data['encoded_prev_items']], batch_first=True)\n",
    "test_sequences = pad_sequence([torch.tensor(seq) for seq in test_data['encoded_prev_items']], batch_first=True)\n",
    "\n",
    "train_targets = torch.tensor(train_data['encoded_next_item'].values)\n",
    "test_targets = torch.tensor(test_data['encoded_next_item'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model without feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class SimpleLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        # Only take the output from the final timestep\n",
    "        out = self.fc(hidden[-1])\n",
    "\n",
    "        # Apply softmax on the output layer to get probabilities\n",
    "        out = F.softmax(out, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minwoo/anaconda3/envs/DS5440/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 10.320464134216309\n",
      "Epoch 2: Loss = 10.320464134216309\n",
      "Epoch 3: Loss = 10.320464134216309\n",
      "Epoch 4: Loss = 10.320464134216309\n",
      "Epoch 5: Loss = 10.320464134216309\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = vocab_size  # Same as the number of unique items\n",
    "model = SimpleLSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5  # Starting with a small number for the baseline model\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictions = model(train_sequences)\n",
    "    loss = loss_function(predictions, train_targets)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Loss = {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/8_5y1g_97cn0gnnv_9ttj6f40000gn/T/ipykernel_38928/1521212704.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_sequences_tensor = torch.tensor(test_sequences, dtype=torch.long)\n",
      "/var/folders/vq/8_5y1g_97cn0gnnv_9ttj6f40000gn/T/ipykernel_38928/1521212704.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_targets_tensor = torch.tensor(test_targets, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming test_sequences and test_targets are lists of integers\n",
    "# Convert lists of sequences and targets into PyTorch tensors\n",
    "test_sequences_tensor = torch.tensor(test_sequences, dtype=torch.long)\n",
    "test_targets_tensor = torch.tensor(test_targets, dtype=torch.long)\n",
    "\n",
    "# Wrap tensors in a TensorDataset\n",
    "test_dataset = TensorDataset(test_sequences_tensor, test_targets_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 64  # Adjust based on your needs\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy on Test Set: 0.009527439024390244%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader, k=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    top_k_accs = []  # Store each batch's Top-K accuracy\n",
    "    \n",
    "    with torch.no_grad():  # No gradients needed during evaluation\n",
    "        for sequences, targets in data_loader:\n",
    "            predictions = model(sequences)\n",
    "            # Call the top_k_accuracy function and store its result in a differently named variable\n",
    "            batch_top_k_accuracy = top_k_accuracy(predictions, targets, k=k)\n",
    "            top_k_accs.append(batch_top_k_accuracy)\n",
    "\n",
    "    # Calculate the average Top-K accuracy across all batches\n",
    "    avg_top_k_acc = sum(top_k_accs) / len(top_k_accs)\n",
    "    return avg_top_k_acc\n",
    "\n",
    "# Make sure you have a function defined for calculating Top-K accuracy\n",
    "def top_k_accuracy(outputs, targets, k=5):\n",
    "    _, predicted = outputs.topk(k, 1, True, True)\n",
    "    correct = predicted.eq(targets.view(-1, 1).expand_as(predicted))\n",
    "    correct_total = correct.view(-1).float().sum(0, keepdim=True)\n",
    "    return correct_total.mul_(100.0 / outputs.size(0)).item()\n",
    "\n",
    "# Assuming test_loader is your DataLoader for the test set\n",
    "avg_top5_acc = evaluate_model(model, test_loader, k=5)\n",
    "print(f\"Average Top-5 Accuracy on Test Set: {avg_top5_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_one_hot(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in data_loader:\n",
    "            predictions = model(sequences)\n",
    "            _, predicted_classes = torch.max(predictions, 1)\n",
    "            correct_predictions += (predicted_classes == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Test Set: 0.0095785%\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_loader is your DataLoader for the test set\n",
    "acc = evaluate_with_one_hot(model, test_loader)\n",
    "print(f\"Accuracy of the Test Set: {acc:.7f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next items: [\"['B01BKMARL8', 'B07ZKDGFMF']\", \"['B09XJ1RZ4Q', 'B09YDDQ3G2']\", \"['B0935DN1BN', 'B0935JRJ59']\", \"['B08PPDTH9L', 'B08PPDTH9L']\", \"['B09DXW29JB', 'B0B2WCXJJV']\"]\n"
     ]
    }
   ],
   "source": [
    "def predict_next_item(model, sequence, item_to_index, index_to_item, k=1):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    \n",
    "    # Process the input sequence\n",
    "    encoded_sequence = [item_to_index[item] for item in sequence if item in item_to_index]\n",
    "    padded_sequence = torch.tensor([encoded_sequence])  # Add a batch dimension and pad if necessary\n",
    "    padded_sequence = pad_sequence(padded_sequence, batch_first=True)  # Assuming you're using pad_sequence for padding\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(padded_sequence)\n",
    "        _, top_k_indices = predictions.topk(k, 1, True, True)\n",
    "        top_k_items = [index_to_item[index.item()] for index in top_k_indices[0]]\n",
    "\n",
    "        \n",
    "\n",
    "    return top_k_items\n",
    "\n",
    "# Example usage\n",
    "sequence = ['B01NCPFGQ3', 'B01N0U5UDH']  # Example sequence of item IDs\n",
    "predicted_items = predict_next_item(model, sequence, item_to_index, index_to_item, k=5)\n",
    "print(f\"Predicted next items: {predicted_items}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>representation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B07PNBPVN1</th>\n",
       "      <td>3.75</td>\n",
       "      <td>[-0.21872417628765106, -0.2500726580619812, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0B45XQ6Q3</th>\n",
       "      <td>8.59</td>\n",
       "      <td>[-0.7130799889564514, -0.5445948839187622, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01CR9IRWY</th>\n",
       "      <td>16.00</td>\n",
       "      <td>[-0.8353576064109802, -0.6093693375587463, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B077RCBS9C</th>\n",
       "      <td>36.98</td>\n",
       "      <td>[-0.8522624969482422, -0.5257986783981323, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B088BMDXPD</th>\n",
       "      <td>7.99</td>\n",
       "      <td>[-0.8538389205932617, -0.47541171312332153, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price                                     representation\n",
       "id                                                                  \n",
       "B07PNBPVN1   3.75  [-0.21872417628765106, -0.2500726580619812, -0...\n",
       "B0B45XQ6Q3   8.59  [-0.7130799889564514, -0.5445948839187622, -0....\n",
       "B01CR9IRWY  16.00  [-0.8353576064109802, -0.6093693375587463, -0....\n",
       "B077RCBS9C  36.98  [-0.8522624969482422, -0.5257986783981323, -0....\n",
       "B088BMDXPD   7.99  [-0.8538389205932617, -0.47541171312332153, -0..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv('products_train_UK_representations.csv')\n",
    "# Ensure 'id' is the index for easy lookup\n",
    "products = products.set_index('id')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associate item in sequences with its price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next_item</th>\n",
       "      <th>prev_items</th>\n",
       "      <th>encoded_prev_items</th>\n",
       "      <th>encoded_next_item</th>\n",
       "      <th>items_with_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0046U4CGS</td>\n",
       "      <td>[B01NCPFGQ3, B01N0U5UDH]</td>\n",
       "      <td>[4024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(B01NCPFGQ3, 8.99), (B01N0U5UDH, 9.48)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07QS8M6W4</td>\n",
       "      <td>[B08HLVKVWR, B00I874D4Q]</td>\n",
       "      <td>[1779, 3370]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(B08HLVKVWR, 9.17), (B00I874D4Q, 3.6)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B094VMJK1G</td>\n",
       "      <td>[B094VLF9QV, B0B24Z4D3V]</td>\n",
       "      <td>[2374]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(B094VLF9QV, 29.93), (B0B24Z4D3V, 58.91)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07YQ1XM6J</td>\n",
       "      <td>[B0177HKHQK, B01HQHGIBY]</td>\n",
       "      <td>[2869, 5891]</td>\n",
       "      <td>3</td>\n",
       "      <td>[(B0177HKHQK, 4.29), (B01HQHGIBY, 3.89)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0B63T3HGD</td>\n",
       "      <td>[B09JXY17B6, B004PYD9QE]</td>\n",
       "      <td>[5401]</td>\n",
       "      <td>4</td>\n",
       "      <td>[(B09JXY17B6, 9.99), (B004PYD9QE, 7.99)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    next_item                prev_items encoded_prev_items  encoded_next_item  \\\n",
       "0  B0046U4CGS  [B01NCPFGQ3, B01N0U5UDH]             [4024]                  0   \n",
       "1  B07QS8M6W4  [B08HLVKVWR, B00I874D4Q]       [1779, 3370]                  1   \n",
       "2  B094VMJK1G  [B094VLF9QV, B0B24Z4D3V]             [2374]                  2   \n",
       "3  B07YQ1XM6J  [B0177HKHQK, B01HQHGIBY]       [2869, 5891]                  3   \n",
       "4  B0B63T3HGD  [B09JXY17B6, B004PYD9QE]             [5401]                  4   \n",
       "\n",
       "                             items_with_price  \n",
       "0    [(B01NCPFGQ3, 8.99), (B01N0U5UDH, 9.48)]  \n",
       "1     [(B08HLVKVWR, 9.17), (B00I874D4Q, 3.6)]  \n",
       "2  [(B094VLF9QV, 29.93), (B0B24Z4D3V, 58.91)]  \n",
       "3    [(B0177HKHQK, 4.29), (B01HQHGIBY, 3.89)]  \n",
       "4    [(B09JXY17B6, 9.99), (B004PYD9QE, 7.99)]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding price to each item in the sequences\n",
    "def add_price_to_sequence(sequence):\n",
    "    # For each item in the sequence, create a tuple (item_id, price)\n",
    "    # If the item ID is not in the products DataFrame, use a default price (e.g., 0 or the mean price)\n",
    "    default_price = products['price'].mean()\n",
    "    return [(item, products.at[item, 'price'] if item in products.index else default_price) for item in sequence]\n",
    "\n",
    "data['items_with_price'] = data['prev_items'].apply(add_price_to_sequence)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next_item</th>\n",
       "      <th>prev_items</th>\n",
       "      <th>encoded_prev_items</th>\n",
       "      <th>encoded_next_item</th>\n",
       "      <th>items_with_price</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0046U4CGS</td>\n",
       "      <td>[B01NCPFGQ3, B01N0U5UDH]</td>\n",
       "      <td>[4024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(B01NCPFGQ3, 8.99), (B01N0U5UDH, 9.48)]</td>\n",
       "      <td>[8.99, 9.48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B07QS8M6W4</td>\n",
       "      <td>[B08HLVKVWR, B00I874D4Q]</td>\n",
       "      <td>[1779, 3370]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(B08HLVKVWR, 9.17), (B00I874D4Q, 3.6)]</td>\n",
       "      <td>[9.17, 3.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B094VMJK1G</td>\n",
       "      <td>[B094VLF9QV, B0B24Z4D3V]</td>\n",
       "      <td>[2374]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(B094VLF9QV, 29.93), (B0B24Z4D3V, 58.91)]</td>\n",
       "      <td>[29.93, 58.91]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B07YQ1XM6J</td>\n",
       "      <td>[B0177HKHQK, B01HQHGIBY]</td>\n",
       "      <td>[2869, 5891]</td>\n",
       "      <td>3</td>\n",
       "      <td>[(B0177HKHQK, 4.29), (B01HQHGIBY, 3.89)]</td>\n",
       "      <td>[4.29, 3.89]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0B63T3HGD</td>\n",
       "      <td>[B09JXY17B6, B004PYD9QE]</td>\n",
       "      <td>[5401]</td>\n",
       "      <td>4</td>\n",
       "      <td>[(B09JXY17B6, 9.99), (B004PYD9QE, 7.99)]</td>\n",
       "      <td>[9.99, 7.99]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    next_item                prev_items encoded_prev_items  encoded_next_item  \\\n",
       "0  B0046U4CGS  [B01NCPFGQ3, B01N0U5UDH]             [4024]                  0   \n",
       "1  B07QS8M6W4  [B08HLVKVWR, B00I874D4Q]       [1779, 3370]                  1   \n",
       "2  B094VMJK1G  [B094VLF9QV, B0B24Z4D3V]             [2374]                  2   \n",
       "3  B07YQ1XM6J  [B0177HKHQK, B01HQHGIBY]       [2869, 5891]                  3   \n",
       "4  B0B63T3HGD  [B09JXY17B6, B004PYD9QE]             [5401]                  4   \n",
       "\n",
       "                             items_with_price          prices  \n",
       "0    [(B01NCPFGQ3, 8.99), (B01N0U5UDH, 9.48)]    [8.99, 9.48]  \n",
       "1     [(B08HLVKVWR, 9.17), (B00I874D4Q, 3.6)]     [9.17, 3.6]  \n",
       "2  [(B094VLF9QV, 29.93), (B0B24Z4D3V, 58.91)]  [29.93, 58.91]  \n",
       "3    [(B0177HKHQK, 4.29), (B01HQHGIBY, 3.89)]    [4.29, 3.89]  \n",
       "4    [(B09JXY17B6, 9.99), (B004PYD9QE, 7.99)]    [9.99, 7.99]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to retrieve prices for a list of item IDs\n",
    "def get_prices(items):\n",
    "    # Retrieve prices for each item, defaulting to a specific price if not found (e.g., mean price)\n",
    "    default_price = products['price'].mean()\n",
    "    return [products.loc[item, 'price'] if item in products.index else default_price for item in items]\n",
    "\n",
    "# Apply the function to each row in the 'prev_items' column\n",
    "data['prices'] = data['prev_items'].apply(get_prices)\n",
    "\n",
    "# View the updated DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique set of all item IDs\n",
    "all_items = set([item for sublist in data['prev_items'] for item in sublist] + data['next_item'].tolist())\n",
    "\n",
    "# Create mappings\n",
    "item_to_index = {item: idx for idx, item in enumerate(all_items)}\n",
    "index_to_item = {idx: item for item, idx in item_to_index.items()}\n",
    "\n",
    "# Encode the sequences and next item\n",
    "data['encoded_prev_items'] = data['prev_items'].apply(lambda x: [item_to_index[item] for item in x])\n",
    "data['encoded_next_item'] = data['next_item'].apply(lambda x: item_to_index[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Price Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMWithPriceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, price_feature_dim=1):\n",
    "        super(LSTMWithPriceModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        # Adjust the LSTM input size to include the price feature\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim + price_feature_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "    \n",
    "    def forward(self, x, prices):\n",
    "        x = self.embedding(x)\n",
    "        # Concatenate item embeddings with price\n",
    "        x = torch.cat((x, prices.unsqueeze(-1)), dim=-1)\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        out = self.fc(hidden[-1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequencePriceDataset(Dataset):\n",
    "    def __init__(self, sequences, prices, targets):\n",
    "        self.sequences = sequences\n",
    "        self.prices = prices\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = torch.tensor(self.sequences[idx], dtype=torch.long)\n",
    "        prices = torch.tensor(self.prices[idx], dtype=torch.float)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.long)\n",
    "        return sequence, prices, target\n",
    "\n",
    "# Extract data from DataFrame for the Dataset\n",
    "sequences = data['encoded_prev_items'].tolist()\n",
    "prices = data['prices'].tolist()\n",
    "targets = data['encoded_next_item'].tolist()\n",
    "\n",
    "# Create dataset and data loader\n",
    "dataset = SequencePriceDataset(sequences, prices, targets)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMWithPriceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LSTMWithPriceModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim + 1, hidden_size=hidden_dim, batch_first=True)  # +1 for the price\n",
    "        self.fc = nn.Linear(in_features=hidden_dim, out_features=output_dim)\n",
    "\n",
    "    def forward(self, sequences, prices):\n",
    "        embedded = self.embedding(sequences)\n",
    "        # Combine prices with embeddings\n",
    "        combined = torch.cat((embedded, prices.unsqueeze(-1)), dim=2)  # Ensure prices are correctly shaped\n",
    "        lstm_out, _ = self.lstm(combined)\n",
    "        output = self.fc(lstm_out[:, -1])  # Get the output of the last time step\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.512721206043281\n",
      "Epoch 2, Loss: 5.046496960900578\n",
      "Epoch 3, Loss: 3.9015308678442358\n",
      "Epoch 4, Loss: 3.227950044706756\n",
      "Epoch 5, Loss: 2.7641912140682634\n",
      "Epoch 6, Loss: 2.4248918405204427\n",
      "Epoch 7, Loss: 2.1720372526084675\n",
      "Epoch 8, Loss: 1.9835269509577285\n",
      "Epoch 9, Loss: 1.8425508270807125\n",
      "Epoch 10, Loss: 1.7341615022981869\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Assuming vocab_size and other parameters are set\n",
    "model = LSTMWithPriceModel(vocab_size=len(item_to_index), embedding_dim=100, hidden_dim=128, output_dim=len(item_to_index))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sequences, prices, targets in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences, prices)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.3981399623421478\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average loss over the dataset\n",
    "total_loss = 0\n",
    "count = 0\n",
    "for sequences, prices, targets in data_loader:\n",
    "    outputs = model(sequences, prices)\n",
    "    loss = criterion(outputs, targets)\n",
    "    total_loss += loss.item()\n",
    "    count += 1\n",
    "average_loss = total_loss / count\n",
    "print(f\"Average Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top k accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 90.15477284730649%\n"
     ]
    }
   ],
   "source": [
    "def top_k_accuracy(outputs, targets, k=5):\n",
    "    with torch.no_grad():\n",
    "        _, predicted = outputs.topk(k, dim=1)\n",
    "        correct = predicted.eq(targets.view(-1, 1).expand_as(predicted))\n",
    "        correct_total = correct.view(-1).float().sum(0, keepdim=True)\n",
    "        return correct_total.mul_(100.0 / outputs.size(0)).item()\n",
    "\n",
    "# Example usage within an evaluation loop:\n",
    "model.eval()\n",
    "top_k_accs = []\n",
    "for sequences, prices, targets in data_loader:\n",
    "    outputs = model(sequences, prices)\n",
    "    top_k_acc = top_k_accuracy(outputs, targets, k=5)\n",
    "    top_k_accs.append(top_k_acc)\n",
    "average_top_k_accuracy = sum(top_k_accs) / len(top_k_accs)\n",
    "print(f\"Average Top-5 Accuracy: {average_top_k_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 60.90%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(outputs, targets):\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct = predicted.eq(targets).sum().item()\n",
    "        accuracy = 100 * correct / targets.size(0)\n",
    "    return accuracy\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# List to hold accuracies for each batch\n",
    "accuracies = []\n",
    "\n",
    "# Evaluate over the entire DataLoader\n",
    "for sequences, prices, targets in data_loader:\n",
    "    # Forward pass\n",
    "    outputs = model(sequences, prices)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = calculate_accuracy(outputs, targets)\n",
    "\n",
    "    # Store the accuracy\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all batches\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Average Accuracy: {average_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
